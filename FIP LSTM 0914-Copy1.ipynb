{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed_value= 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "#Scikit-Learn Importing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Import PyWavelets for WaveSmoothing\n",
    "import pywt\n",
    "import mad\n",
    "from statsmodels import robust\n",
    "\n",
    "#Import Keras\n",
    "import keras\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, LSTM, RepeatVector, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD, Adadelta\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "from keras import backend as K\n",
    "\n",
    "#Import Gridsearch\n",
    "from hypopt import GridSearch\n",
    "\n",
    "#Import Capstone Functions\n",
    "from Capstone_Functions import *\n",
    "cf = CapstoneFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Monthly = pd.read_pickle('data/Monthly.pkl')\n",
    "Monthly2 = pd.read_pickle('data/MonthlyReturns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WOMonthly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-12-03</th>\n",
       "      <td>0.052244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-01-01</th>\n",
       "      <td>0.011277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02-01</th>\n",
       "      <td>0.015239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03-01</th>\n",
       "      <td>0.096461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-01</th>\n",
       "      <td>0.026566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WOMonthly\n",
       "date                 \n",
       "1990-12-03   0.052244\n",
       "1991-01-01   0.011277\n",
       "1991-02-01   0.015239\n",
       "1991-03-01   0.096461\n",
       "1991-04-01   0.026566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOMonthly = Monthly.iloc[:,14:15].copy()\n",
    "WOMonthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPMonthly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-12-03</th>\n",
       "      <td>0.034620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-01-01</th>\n",
       "      <td>0.022021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02-01</th>\n",
       "      <td>0.013218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03-01</th>\n",
       "      <td>0.089188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-01</th>\n",
       "      <td>0.031861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FIPMonthly\n",
       "date                  \n",
       "1990-12-03    0.034620\n",
       "1991-01-01    0.022021\n",
       "1991-02-01    0.013218\n",
       "1991-03-01    0.089188\n",
       "1991-04-01    0.031861"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIPMonthly = Monthly2.iloc[:,16:17].copy()\n",
    "FIPMonthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIPMonthly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Train_Test_Split for High and Low Momentum returns with a 60 Month Lookback\n",
    "WOXdata, WOYdata, WOXtrain, WOYtrain, WOXtest, WOYtest, WOPredictedX, WOForecastX, WOX, WOY = \\\n",
    "cf.Train_Test_Split(WOMonthly, 0, 100, 12, scaler = False)\n",
    "\n",
    "FIPXdata, FIPYdata, FIPXtrain, FIPYtrain, FIPXtest, FIPYtest, FIPPredictedX, FIPForecastX, FIPX, FIPY = \\\n",
    "cf.Train_Test_Split(FIPMonthly, 0, 100, 12, scaler = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveletSmooth(x, wavelet=\"haar\", level=2, DecLvl=2):\n",
    "    # calculate the wavelet coefficients\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\", level=DecLvl)\n",
    "    # calculate a threshold\n",
    "    sigma = robust.mad(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x )))\n",
    "    coeff[1:] = (pywt.threshold( i, value=uthresh, mode=\"soft\" ) for i in coeff[1:])\n",
    "    # reconstruct the signal using the thresholded coefficients\n",
    "    y = pywt.waverec(coeff, wavelet, mode=\"per\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_wo = waveletSmooth(WOMonthly.iloc[:,0])\n",
    "wav_wo = wav_wo.reshape(len(wav_wo),1)\n",
    "\n",
    "wav_fip = waveletSmooth(FIPMonthly.iloc[:,0])\n",
    "wav_fip = wav_fip.reshape(len(wav_fip),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def Train_Test_Split2(Data1, Hi_or_Lo, Window, Lookback): \n",
    "\n",
    "        \"\"\" \n",
    "        Import Monthly data with Date as Index. Select which portfolio to train test split. Set number of\n",
    "        lookback months and whether to use MinMaxScaler.\n",
    "\n",
    "        Example:\n",
    "        HiXdata, HiYdata, HiXtrain, HiYtrain, HiXtest, HiYtest, HiPredictedX, HiForecastX, HiX, HiY = \\\n",
    "        Train_Test_Split(Monthly, 'Hi', 60, 12, scaler = False)\n",
    "\n",
    "        \"\"\" \n",
    "\n",
    "\n",
    "        #If High or Low Momentum Portfolio\n",
    "        if Hi_or_Lo == 'Hi':\n",
    "            Port = 0\n",
    "        else:\n",
    "            Port =  0\n",
    "\n",
    "        TrainSplit = int(Window*0.9)\n",
    "        TestSplit = int(Window*0.1)\n",
    "\n",
    "        #Iterate Through Data and Creat Numpy arrays with 12 Months of \\ \n",
    "        #lagged data for X and 13th Month for Y\n",
    "        tmpX=[]\n",
    "        tmpY=[]\n",
    "        for A in range(len(Data1)-Lookback):\n",
    "            tmp=Data1[A:(A + Lookback),Port]\n",
    "            tmpX.append(tmp)\n",
    "            tmpY.append(Data1[(A + Lookback),Port])\n",
    "        Xdata = np.array(tmpX)\n",
    "        Ydata = np.array(tmpY)\n",
    "\n",
    "        tmpForeX=[]\n",
    "        for A in range(len(Data1)-Lookback):\n",
    "            tmpFore=Data1[A+1:(A+1 + Lookback),Port]\n",
    "            tmpForeX.append(tmpFore)\n",
    "        XdataFore = np.array(tmpForeX)\n",
    "\n",
    "        Ydata = Ydata.reshape(len(Ydata),1)\n",
    "\n",
    "        Shape = int(Xdata.shape[0])\n",
    "        Shape2 = int(XdataFore.shape[0])\n",
    "\n",
    "\n",
    "        #Create Empty Numpy Arrays\n",
    "        Xtrain=np.ones(shape=(Shape-Window,TrainSplit,12))\n",
    "        Ytrain=np.ones(shape=(Shape-Window,TrainSplit,1))\n",
    "        Xtest=np.ones(shape=(Shape-Window,TestSplit,Lookback))\n",
    "        Ytest=np.ones(shape=(Shape-Window,TestSplit,1))\n",
    "        PredictedX=np.ones(shape=(Shape-Window,1,Lookback))\n",
    "        ForecastX=np.ones(shape=(Shape2-Window,1,Lookback))\n",
    "        X = np.ones(shape=(Shape-Window,Window,Lookback))\n",
    "        Y = np.ones(shape=(Shape-Window,Window,1))\n",
    "\n",
    "        #Fill Numpy Arrays with data\n",
    "        for B in range(Shape-Window):\n",
    "            Xtrain[B,:,:] = Xdata[B:B+TrainSplit,:]\n",
    "            Ytrain[B,:,:] = Ydata[B:B+TrainSplit]\n",
    "            Xtest[B,:,:] = Xdata[B+TrainSplit:B+Window,:]\n",
    "            Ytest[B,:,:] = Ydata[B+TrainSplit:B+Window]\n",
    "            PredictedX[B,:,:] = Xdata[B+Window,:]\n",
    "            ForecastX[B,:,:] = XdataFore[B+Window,:]\n",
    "            X[B,:,:] = Xdata[B:B+Window,:]\n",
    "            Y[B,:,:] = Ydata[B:B+Window]\n",
    "\n",
    "        return Xdata, Ydata, Xtrain, Ytrain, Xtest, Ytest, PredictedX, ForecastX, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Train_Test_Split for High and Low Momentum returns with a 60 Month Lookback\n",
    "W_WO_Xdata, W_WO_Ydata, W_WO_Xtrain, W_WO_Ytrain, W_WO_Xtest, W_WO_Ytest, W_WO_ForecastX, \\\n",
    "W_WO_ForecastX, W_WO_X, W_WO_Y = \\\n",
    "Train_Test_Split2(wav_wo, 'Hi', 100, 12)\n",
    "\n",
    "#Create Train_Test_Split for High and Low Momentum returns with a 60 Month Lookback\n",
    "W_FIP_Xdata, W_FIP_Ydata, W_FIP_Xtrain, W_FIP_Ytrain, W_FIP_Xtest, W_FIP_Ytest, W_FIP_ForecastX,\\\n",
    "W_FIP_ForecastX, W_FIP_X, W_FIP_Y = \\\n",
    "Train_Test_Split2(wav_fip, 'Hi', 100, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Reshape(LSTM_Shape):\n",
    "    LSTM_Shape = LSTM_Shape.reshape((LSTM_Shape.shape[0],LSTM_Shape.shape[1],1))\n",
    "    return LSTM_Shape\n",
    "\n",
    "def LSTM_RNN(Xtrain, Ytrain, Xtest, Ytest, Xtrue):\n",
    "    keras.backend.clear_session()\n",
    "    LSTM_ = Sequential()\n",
    "    LSTM_.add(LSTM(8, input_shape = (12,1), return_sequences = True))\n",
    "    LSTM_.add(Dropout(0.2))\n",
    "    LSTM_.add(LSTM(8, return_sequences = True))\n",
    "    LSTM_.add(Dropout(0.2))\n",
    "    LSTM_.add(LSTM(8, return_sequences = False))\n",
    "    LSTM_.add(Dropout(0.2))\n",
    "    LSTM_.add(Dense(1, activation = 'linear'))\n",
    "    LSTM_.compile(loss='mse', optimizer = Adam(lr = 0.05))\n",
    "    LSTM_.fit(Xtrain, Ytrain, batch_size = batch, epochs = epochs,\n",
    "       validation_data = (Xtest, Ytest), shuffle = False, verbose = 0, stateful = True)\n",
    "    Prediction_ = LSTM_.predict(Xtrue)\n",
    "    history = LSTM_.fit(Xtrain, Ytrain, batch_size = batch, epochs = epochs,\n",
    "       validation_data = (Xtest, Ytest), shuffle = False, verbose = 0, stateful = True)\n",
    "    Prediction_ = LSTM_.predict(Xtrue)\n",
    "    \n",
    "    print(history.history.keys())\n",
    "   \n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'test'], loc='upper left')  \n",
    "    plt.show()\n",
    "    \n",
    "    return (Prediction_)\n",
    "\n",
    "def predictLSTM(Xtrain, Ytrain, Xtest, Ytest, XFore):\n",
    "    Final_Prediction = np.zeros(shape=(244,1))\n",
    "    for i in range(Final_Prediction.shape[0]):\n",
    "        Xtrain_Reshape = LSTM_Reshape(Xtrain[i])\n",
    "        Xtest_Reshape = LSTM_Reshape(Xtest[i])\n",
    "        XFore_Reshape = LSTM_Reshape(XFore[i])\n",
    "        Final_Prediction[i] = LSTM_RNN(Xtrain_Reshape, Ytrain[i], Xtest_Reshape, Ytest[i], XFore_Reshape)\n",
    "        print('Prediction',i+1,'of',244)\n",
    "    return Final_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unrecognized keyword arguments: {'stateful': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-35988ff6b8c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_FIP_LSTM\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_FIP_Xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIPYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_FIP_Xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIPYtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_FIP_ForecastX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-142516cb18c3>\u001b[0m in \u001b[0;36mpredictLSTM\u001b[0;34m(Xtrain, Ytrain, Xtest, Ytest, XFore)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mXtest_Reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_Reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mXFore_Reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_Reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXFore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mFinal_Prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_Reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest_Reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXFore_Reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'of'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m244\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFinal_Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-142516cb18c3>\u001b[0m in \u001b[0;36mLSTM_RNN\u001b[0;34m(Xtrain, Ytrain, Xtest, Ytest, Xtrue)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mLSTM_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     LSTM_.fit(Xtrain, Ytrain, batch_size = batch, epochs = epochs,\n\u001b[0;32m---> 17\u001b[0;31m        validation_data = (Xtest, Ytest), shuffle = False, verbose = 0, stateful = True)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mPrediction_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     history = LSTM_.fit(Xtrain, Ytrain, batch_size = batch, epochs = epochs,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nb_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'stateful': True}"
     ]
    }
   ],
   "source": [
    "pred_FIP_LSTM = \\\n",
    "predictLSTM(W_FIP_Xtrain, FIPYtrain, W_FIP_Xtest, FIPYtest, W_FIP_ForecastX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_FIP_Forecast = pd.DataFrame(pred_FIP_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_FIP_Forecast.to_pickle('data/LSTM_FIP_Forecast.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
