{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed_value= 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import pickle\n",
    "\n",
    "#Scikit-Learn Importing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Import PyWavelets for WaveSmoothing\n",
    "import pywt\n",
    "import mad\n",
    "from statsmodels import robust\n",
    "\n",
    "#Import Keras\n",
    "import keras\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, LSTM, RepeatVector, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD, Adadelta\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "\n",
    "#Import Gridsearch\n",
    "from hypopt import GridSearch\n",
    "\n",
    "#Import Capstone Functions\n",
    "from Capstone_Functions import *\n",
    "cf = CapstoneFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Monthly = pd.read_pickle('data/Monthly.pkl')\n",
    "Monthly2 = pd.read_pickle('data/MonthlyReturns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WOMonthly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-02</th>\n",
       "      <td>-0.050345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>-0.177528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>0.103999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>0.080806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>-0.000094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WOMonthly\n",
       "date                 \n",
       "2020-03-02  -0.050345\n",
       "2020-04-01  -0.177528\n",
       "2020-05-01   0.103999\n",
       "2020-06-01   0.080806\n",
       "2020-07-01  -0.000094"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOMonthly = Monthly.iloc[:,14:15].copy()\n",
    "WOMonthly.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPMonthly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-12-03</th>\n",
       "      <td>0.034620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-01-01</th>\n",
       "      <td>0.022021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02-01</th>\n",
       "      <td>0.013218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03-01</th>\n",
       "      <td>0.089188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-01</th>\n",
       "      <td>0.031861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FIPMonthly\n",
       "date                  \n",
       "1990-12-03    0.034620\n",
       "1991-01-01    0.022021\n",
       "1991-02-01    0.013218\n",
       "1991-03-01    0.089188\n",
       "1991-04-01    0.031861"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIPMonthly = Monthly2.iloc[:,16:17].copy()\n",
    "FIPMonthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split2(Data1, Port, Window, Lookback, scaler): \n",
    "\n",
    "        \"\"\" \n",
    "        Import Monthly data with Date as Index. Select which portfolio to train test split. Set number of\n",
    "        lookback months and whether to use MinMaxScaler.\n",
    "\n",
    "        Example:\n",
    "        HiXdata, HiYdata, HiXtrain, HiYtrain, HiXtest, HiYtest, HiPredictedX, HiForecastX, HiX, HiY = \\\n",
    "        Train_Test_Split(Monthly, 'Hi', 60, 12, scaler = False)\n",
    "\n",
    "        \"\"\" \n",
    "\n",
    "\n",
    "        Data1 = Data1.values\n",
    "\n",
    "        TrainSplit = int(Window*0.90)\n",
    "        TestSplit = int(Window*0.1)\n",
    "\n",
    "        #Iterate Through Data and Creat Numpy arrays with 12 Months of \\ \n",
    "        #lagged data for X and 13th Month for Y\n",
    "        tmpX=[]\n",
    "        tmpY=[]\n",
    "        for A in range(len(Data1)-Lookback):\n",
    "            tmp=Data1[A:(A + Lookback),Port]\n",
    "            tmpX.append(tmp)\n",
    "            tmpY.append(Data1[(A + Lookback),Port])\n",
    "        Xdata = np.array(tmpX)\n",
    "        Ydata = np.array(tmpY)\n",
    "\n",
    "        tmpForeX=[]\n",
    "        for A in range(len(Data1)-Lookback):\n",
    "            tmpFore=Data1[A+1:(A+1 + Lookback),Port]\n",
    "            tmpForeX.append(tmpFore)\n",
    "        XdataFore = np.array(tmpForeX)\n",
    "\n",
    "        Ydata = Ydata.reshape(len(Ydata),1)\n",
    "\n",
    "        Shape = int(Xdata.shape[0])\n",
    "        Shape2 = int(XdataFore.shape[0])\n",
    "\n",
    "\n",
    "        #Create Empty Numpy Arrays\n",
    "        Xtrain=np.ones(shape=(Shape-Window,TrainSplit+TestSplit,12))\n",
    "        Ytrain=np.ones(shape=(Shape-Window,TrainSplit+TestSplit,1))\n",
    "        Xtest=np.ones(shape=(Shape-Window,TestSplit,Lookback))\n",
    "        Ytest=np.ones(shape=(Shape-Window,TestSplit,1))\n",
    "        PredictedX=np.ones(shape=(Shape-Window,1,Lookback))\n",
    "        ForecastX=np.ones(shape=(Shape2-Window,1,Lookback))\n",
    "        X = np.ones(shape=(Shape-Window,Window,Lookback))\n",
    "        Y = np.ones(shape=(Shape-Window,Window,1))\n",
    "\n",
    "        #Fill Numpy Arrays with data\n",
    "        for B in range(Shape-Window):\n",
    "            Xtrain[B,:,:] = Xdata[B:B+TrainSplit+TestSplit,:]\n",
    "            Ytrain[B,:,:] = Ydata[B:B+TrainSplit+TestSplit]\n",
    "            Xtest[B,:,:] = Xdata[B+TrainSplit:B+Window,:]\n",
    "            Ytest[B,:,:] = Ydata[B+TrainSplit:B+Window]\n",
    "            PredictedX[B,:,:] = Xdata[B+Window,:]\n",
    "            ForecastX[B,:,:] = XdataFore[B+Window,:]\n",
    "            X[B,:,:] = Xdata[B:B+Window,:]\n",
    "            Y[B,:,:] = Ydata[B:B+Window]\n",
    "\n",
    "            if scaler:\n",
    "                sc = MinMaxScaler()\n",
    "                Xtrain[B,:,:] = sc.fit_transform(Xtrain[B,:,:])\n",
    "                Xtest[B,:,:] = sc.transform(Xtest[B,:,:])\n",
    "                PredictedX[B,:,:] = sc.transform(PredictedX[B,:,:])\n",
    "                X[B,:,:] = sc.transform(X[B,:,:])\n",
    "\n",
    "\n",
    "\n",
    "        return Xdata, Ydata, Xtrain, Ytrain, Xtest, Ytest, PredictedX, ForecastX, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Train_Test_Split for High and Low Momentum returns with a 60 Month Lookback\n",
    "WOXdata, WOYdata, WOXtrain, WOYtrain, WOXtest, WOYtest, WOPredictedX, WOForecastX, WOX, WOY = \\\n",
    "Train_Test_Split2(WOMonthly, 0, 100, 12, scaler = False)\n",
    "\n",
    "FIPXdata, FIPYdata, FIPXtrain, FIPYtrain, FIPXtest, FIPYtest, FIPPredictedX, FIPForecastX, FIPX, FIPY = \\\n",
    "Train_Test_Split2(FIPMonthly, 0, 100, 12, scaler = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=np.power([10,10,10,10,10],np.linspace(-5,-1,5))\n",
    "grid=np.append(grid, 5*grid)\n",
    "\n",
    "cgrid=np.power([10,10,10,10,10,10],np.linspace(-2,3,6))\n",
    "cgrid=np.append(cgrid, 5*cgrid)\n",
    "\n",
    "rbf = ['rbf']\n",
    "parameters = {'gamma': grid, 'C': cgrid, 'epsilon': grid, 'kernel':['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSVR2(Xtrain, Ytrain, PredictedX):\n",
    "    #param_grid = [parameters]\n",
    "    final_pred = np.zeros(shape=(244,1))\n",
    "    for X in range(final_pred.shape[0]):\n",
    "        gs = GridSearch(model = SVR(), param_grid = parameters)\n",
    "        gs.fit(Xtrain[X], Ytrain[X].ravel(), scoring ='neg_mean_squared_error')\n",
    "        final_pred[X] = gs.predict(PredictedX[X,:])\n",
    "        print('Forecast',X+1,'of',244)\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast 1 of 244\n",
      "Forecast 2 of 244\n",
      "Forecast 3 of 244\n",
      "Forecast 4 of 244\n",
      "Forecast 5 of 244\n",
      "Forecast 6 of 244\n",
      "Forecast 7 of 244\n",
      "Forecast 8 of 244\n",
      "Forecast 9 of 244\n",
      "Forecast 10 of 244\n",
      "Forecast 11 of 244\n",
      "Forecast 12 of 244\n",
      "Forecast 13 of 244\n",
      "Forecast 14 of 244\n",
      "Forecast 15 of 244\n",
      "Forecast 16 of 244\n",
      "Forecast 17 of 244\n",
      "Forecast 18 of 244\n",
      "Forecast 19 of 244\n",
      "Forecast 20 of 244\n",
      "Forecast 21 of 244\n",
      "Forecast 22 of 244\n",
      "Forecast 23 of 244\n",
      "Forecast 24 of 244\n",
      "Forecast 25 of 244\n",
      "Forecast 26 of 244\n",
      "Forecast 27 of 244\n",
      "Forecast 28 of 244\n",
      "Forecast 29 of 244\n",
      "Forecast 30 of 244\n",
      "Forecast 31 of 244\n",
      "Forecast 32 of 244\n",
      "Forecast 33 of 244\n",
      "Forecast 34 of 244\n",
      "Forecast 35 of 244\n",
      "Forecast 36 of 244\n",
      "Forecast 37 of 244\n",
      "Forecast 38 of 244\n",
      "Forecast 39 of 244\n",
      "Forecast 40 of 244\n",
      "Forecast 41 of 244\n",
      "Forecast 42 of 244\n",
      "Forecast 43 of 244\n",
      "Forecast 44 of 244\n",
      "Forecast 45 of 244\n",
      "Forecast 46 of 244\n",
      "Forecast 47 of 244\n",
      "Forecast 48 of 244\n",
      "Forecast 49 of 244\n",
      "Forecast 50 of 244\n",
      "Forecast 51 of 244\n",
      "Forecast 52 of 244\n",
      "Forecast 53 of 244\n",
      "Forecast 54 of 244\n",
      "Forecast 55 of 244\n",
      "Forecast 56 of 244\n",
      "Forecast 57 of 244\n",
      "Forecast 58 of 244\n",
      "Forecast 59 of 244\n",
      "Forecast 60 of 244\n",
      "Forecast 61 of 244\n",
      "Forecast 62 of 244\n",
      "Forecast 63 of 244\n",
      "Forecast 64 of 244\n",
      "Forecast 65 of 244\n",
      "Forecast 66 of 244\n",
      "Forecast 67 of 244\n",
      "Forecast 68 of 244\n",
      "Forecast 69 of 244\n",
      "Forecast 70 of 244\n",
      "Forecast 71 of 244\n",
      "Forecast 72 of 244\n",
      "Forecast 73 of 244\n",
      "Forecast 74 of 244\n",
      "Forecast 75 of 244\n",
      "Forecast 76 of 244\n",
      "Forecast 77 of 244\n",
      "Forecast 78 of 244\n",
      "Forecast 79 of 244\n",
      "Forecast 80 of 244\n",
      "Forecast 81 of 244\n",
      "Forecast 82 of 244\n",
      "Forecast 83 of 244\n",
      "Forecast 84 of 244\n",
      "Forecast 85 of 244\n",
      "Forecast 86 of 244\n",
      "Forecast 87 of 244\n",
      "Forecast 88 of 244\n",
      "Forecast 89 of 244\n",
      "Forecast 90 of 244\n",
      "Forecast 91 of 244\n",
      "Forecast 92 of 244\n",
      "Forecast 93 of 244\n",
      "Forecast 94 of 244\n",
      "Forecast 95 of 244\n",
      "Forecast 96 of 244\n",
      "Forecast 97 of 244\n",
      "Forecast 98 of 244\n",
      "Forecast 99 of 244\n",
      "Forecast 100 of 244\n",
      "Forecast 101 of 244\n",
      "Forecast 102 of 244\n",
      "Forecast 103 of 244\n",
      "Forecast 104 of 244\n",
      "Forecast 105 of 244\n",
      "Forecast 106 of 244\n",
      "Forecast 107 of 244\n",
      "Forecast 108 of 244\n",
      "Forecast 109 of 244\n",
      "Forecast 110 of 244\n",
      "Forecast 111 of 244\n",
      "Forecast 112 of 244\n",
      "Forecast 113 of 244\n",
      "Forecast 114 of 244\n",
      "Forecast 115 of 244\n",
      "Forecast 116 of 244\n",
      "Forecast 117 of 244\n",
      "Forecast 118 of 244\n",
      "Forecast 119 of 244\n",
      "Forecast 120 of 244\n",
      "Forecast 121 of 244\n",
      "Forecast 122 of 244\n",
      "Forecast 123 of 244\n",
      "Forecast 124 of 244\n",
      "Forecast 125 of 244\n",
      "Forecast 126 of 244\n",
      "Forecast 127 of 244\n",
      "Forecast 128 of 244\n",
      "Forecast 129 of 244\n",
      "Forecast 130 of 244\n",
      "Forecast 131 of 244\n",
      "Forecast 132 of 244\n",
      "Forecast 133 of 244\n",
      "Forecast 134 of 244\n",
      "Forecast 135 of 244\n",
      "Forecast 136 of 244\n",
      "Forecast 137 of 244\n",
      "Forecast 138 of 244\n",
      "Forecast 139 of 244\n",
      "Forecast 140 of 244\n",
      "Forecast 141 of 244\n",
      "Forecast 142 of 244\n",
      "Forecast 143 of 244\n",
      "Forecast 144 of 244\n",
      "Forecast 145 of 244\n",
      "Forecast 146 of 244\n",
      "Forecast 147 of 244\n",
      "Forecast 148 of 244\n",
      "Forecast 149 of 244\n",
      "Forecast 150 of 244\n",
      "Forecast 151 of 244\n",
      "Forecast 152 of 244\n",
      "Forecast 153 of 244\n",
      "Forecast 154 of 244\n",
      "Forecast 155 of 244\n",
      "Forecast 156 of 244\n",
      "Forecast 157 of 244\n",
      "Forecast 158 of 244\n",
      "Forecast 159 of 244\n",
      "Forecast 160 of 244\n",
      "Forecast 161 of 244\n",
      "Forecast 162 of 244\n",
      "Forecast 163 of 244\n",
      "Forecast 164 of 244\n",
      "Forecast 165 of 244\n",
      "Forecast 166 of 244\n",
      "Forecast 167 of 244\n",
      "Forecast 168 of 244\n",
      "Forecast 169 of 244\n",
      "Forecast 170 of 244\n",
      "Forecast 171 of 244\n",
      "Forecast 172 of 244\n",
      "Forecast 173 of 244\n",
      "Forecast 174 of 244\n",
      "Forecast 175 of 244\n",
      "Forecast 176 of 244\n",
      "Forecast 177 of 244\n",
      "Forecast 178 of 244\n",
      "Forecast 179 of 244\n",
      "Forecast 180 of 244\n",
      "Forecast 181 of 244\n",
      "Forecast 182 of 244\n",
      "Forecast 183 of 244\n",
      "Forecast 184 of 244\n",
      "Forecast 185 of 244\n",
      "Forecast 186 of 244\n",
      "Forecast 187 of 244\n",
      "Forecast 188 of 244\n",
      "Forecast 189 of 244\n",
      "Forecast 190 of 244\n",
      "Forecast 191 of 244\n",
      "Forecast 192 of 244\n",
      "Forecast 193 of 244\n",
      "Forecast 194 of 244\n",
      "Forecast 195 of 244\n",
      "Forecast 196 of 244\n",
      "Forecast 197 of 244\n",
      "Forecast 198 of 244\n",
      "Forecast 199 of 244\n",
      "Forecast 200 of 244\n",
      "Forecast 201 of 244\n",
      "Forecast 202 of 244\n",
      "Forecast 203 of 244\n",
      "Forecast 204 of 244\n",
      "Forecast 205 of 244\n",
      "Forecast 206 of 244\n",
      "Forecast 207 of 244\n",
      "Forecast 208 of 244\n",
      "Forecast 209 of 244\n",
      "Forecast 210 of 244\n",
      "Forecast 211 of 244\n",
      "Forecast 212 of 244\n",
      "Forecast 213 of 244\n",
      "Forecast 214 of 244\n",
      "Forecast 215 of 244\n",
      "Forecast 216 of 244\n",
      "Forecast 217 of 244\n",
      "Forecast 218 of 244\n",
      "Forecast 219 of 244\n",
      "Forecast 220 of 244\n",
      "Forecast 221 of 244\n",
      "Forecast 222 of 244\n",
      "Forecast 223 of 244\n",
      "Forecast 224 of 244\n",
      "Forecast 225 of 244\n",
      "Forecast 226 of 244\n",
      "Forecast 227 of 244\n",
      "Forecast 228 of 244\n",
      "Forecast 229 of 244\n",
      "Forecast 230 of 244\n",
      "Forecast 231 of 244\n",
      "Forecast 232 of 244\n",
      "Forecast 233 of 244\n",
      "Forecast 234 of 244\n",
      "Forecast 235 of 244\n",
      "Forecast 236 of 244\n",
      "Forecast 237 of 244\n",
      "Forecast 238 of 244\n",
      "Forecast 239 of 244\n",
      "Forecast 240 of 244\n",
      "Forecast 241 of 244\n",
      "Forecast 242 of 244\n",
      "Forecast 243 of 244\n",
      "Forecast 244 of 244\n"
     ]
    }
   ],
   "source": [
    "Forecast_WOMonthly_SVR = predictSVR2(WOXtrain, WOYtrain, WOForecastX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_WO_Forecast = pd.DataFrame(Forecast_WOMonthly_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_WO_Forecast.to_pickle('data/SVR_WO_Forecast.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
